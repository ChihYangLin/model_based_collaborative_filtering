{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from surprise import SVD, SlopeOne, CoClustering, NMF, NormalPredictor, BaselineOnly\n",
    "from surprise import KNNWithZScore, KNNBasic, KNNBaseline, KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big data\\anaconda3\\envs\\recommendation_system\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>invoice_time</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_code</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>沙威隆抗菌潔淨沐浴乳茶樹精油</td>\n",
       "      <td>82580</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>美妝護理_個人清潔_沐浴用品_沐浴乳</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>韓國鄉村泡菜</td>\n",
       "      <td>82583</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>生鮮食品_冷藏食品_調理食品_沙拉．味噌．泡菜．醬料</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>瑪榭舒適萊卡透氣襪-女(紅)-紅色</td>\n",
       "      <td>21774</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>服飾鞋包_流行鞋襪_襪子_女襪</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>康寶全新鮮味炒手素食500g</td>\n",
       "      <td>21787</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>米油沖泡_調味品．罐頭．湯品_調味粉．醬_味精</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id gender  invoice_no invoice_date invoice_time  \\\n",
       "0           1   Male      536544   2018-11-29     14:32:00   \n",
       "1           1   Male      536544   2018-11-29     14:32:00   \n",
       "2           1   Male      536544   2018-11-29     14:32:00   \n",
       "3           1   Male      536544   2018-11-29     14:32:00   \n",
       "4           1   Male      536544   2018-11-29     14:32:00   \n",
       "\n",
       "         product_name product_code  unit_price  quantity  subtotal  region_id  \\\n",
       "0  王子麵-火鍋/滷味專用50g*5入組        22469          35         3       105        324   \n",
       "1      沙威隆抗菌潔淨沐浴乳茶樹精油        82580         149         1       149        324   \n",
       "2              韓國鄉村泡菜        82583         255         1       255        324   \n",
       "3   瑪榭舒適萊卡透氣襪-女(紅)-紅色        21774          59         1        59        324   \n",
       "4      康寶全新鮮味炒手素食500g        21787         165         1       165        324   \n",
       "\n",
       "  region_name               category_name            date_time  \n",
       "0         平鎮區    米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2018-11-29 14:32:00  \n",
       "1         平鎮區          美妝護理_個人清潔_沐浴用品_沐浴乳  2018-11-29 14:32:00  \n",
       "2         平鎮區  生鮮食品_冷藏食品_調理食品_沙拉．味噌．泡菜．醬料  2018-11-29 14:32:00  \n",
       "3         平鎮區             服飾鞋包_流行鞋襪_襪子_女襪  2018-11-29 14:32:00  \n",
       "4         平鎮區     米油沖泡_調味品．罐頭．湯品_調味粉．醬_味精  2018-11-29 14:32:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取資料\n",
    "df = pd.read_csv(\"retail_data_1029_2020.csv\",encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增一欄商品購買率(某商品總數量 / 全商品總數量)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>invoice_time</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_code</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>date_time</th>\n",
       "      <th>bought_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>Female</td>\n",
       "      <td>539453</td>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>17:08:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>320</td>\n",
       "      <td>中壢區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2018-12-15 17:08:00</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>561820</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>333</td>\n",
       "      <td>龜山區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2019-07-27 16:00:00</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009</td>\n",
       "      <td>Male</td>\n",
       "      <td>562417</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>16:32:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>327</td>\n",
       "      <td>新屋區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2019-08-02 16:32:00</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010</td>\n",
       "      <td>Female</td>\n",
       "      <td>562420</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>16:38:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>320</td>\n",
       "      <td>中壢區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2019-08-02 16:38:00</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  gender  invoice_no invoice_date invoice_time  \\\n",
       "0           1    Male      536544   2018-11-29     14:32:00   \n",
       "1         100  Female      539453   2018-12-15     17:08:00   \n",
       "2        1000    Male      561820   2019-07-27     16:00:00   \n",
       "3        1009    Male      562417   2019-08-02     16:32:00   \n",
       "4        1010  Female      562420   2019-08-02     16:38:00   \n",
       "\n",
       "         product_name product_code  unit_price  quantity  subtotal  region_id  \\\n",
       "0  王子麵-火鍋/滷味專用50g*5入組        22469          35         3       105        324   \n",
       "1  王子麵-火鍋/滷味專用50g*5入組        22469          35         4       140        320   \n",
       "2  王子麵-火鍋/滷味專用50g*5入組        22469          35         1        35        333   \n",
       "3  王子麵-火鍋/滷味專用50g*5入組        22469          35         4       140        327   \n",
       "4  王子麵-火鍋/滷味專用50g*5入組        22469          35         1        35        320   \n",
       "\n",
       "  region_name             category_name            date_time  bought_rate  \n",
       "0         平鎮區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2018-11-29 14:32:00     0.002732  \n",
       "1         中壢區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2018-12-15 17:08:00     0.002732  \n",
       "2         龜山區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2019-07-27 16:00:00     0.002732  \n",
       "3         新屋區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2019-08-02 16:32:00     0.002732  \n",
       "4         中壢區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2019-08-02 16:38:00     0.002732  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 商品購買率的 DataFrame\n",
    "quantity_total = df['quantity'].sum()\n",
    "buy_rate_df = df.groupby('product_code').agg({'quantity': lambda x : (x.sum())/quantity_total})\n",
    "buy_rate_df.rename(columns={'quantity':'bought_rate'}, inplace=True)\n",
    "\n",
    "# 將購買率於原資料做合併\n",
    "df = pd.merge(df,buy_rate_df, on='product_code')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依照欄位數值大小, 均分成五等分, 依大小回傳1, 2, 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'invoice_no': {0.2: 545530.0, 0.4: 555851.0, 0.6: 565401.0, 0.8: 573904.0}, 'unit_price': {0.2: 69.0, 0.4: 109.0, 0.6: 166.0, 0.8: 279.0}, 'quantity': {0.2: 1.0, 0.4: 1.0, 0.6: 2.0, 0.8: 3.0}, 'subtotal': {0.2: 109.0, 0.4: 198.0, 0.6: 338.0, 0.8: 660.0}, 'region_id': {0.2: 325.0, 0.4: 328.0, 0.6: 333.0, 0.8: 336.0}, 'bought_rate': {0.2: 0.00020217995646609, 0.4: 0.0004165885393313387, 0.6: 0.0007198584740304738, 0.8: 0.0013736823655054907}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>invoice_time</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_code</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>date_time</th>\n",
       "      <th>bought_rate</th>\n",
       "      <th>quantity_quartile</th>\n",
       "      <th>price_quartile</th>\n",
       "      <th>bought_rate_quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>536544</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>14:32:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>324</td>\n",
       "      <td>平鎮區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2018-11-29 14:32:00</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>Female</td>\n",
       "      <td>539453</td>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>17:08:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>320</td>\n",
       "      <td>中壢區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2018-12-15 17:08:00</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>561820</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>333</td>\n",
       "      <td>龜山區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2019-07-27 16:00:00</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009</td>\n",
       "      <td>Male</td>\n",
       "      <td>562417</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>16:32:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>327</td>\n",
       "      <td>新屋區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2019-08-02 16:32:00</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010</td>\n",
       "      <td>Female</td>\n",
       "      <td>562420</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>16:38:00</td>\n",
       "      <td>王子麵-火鍋/滷味專用50g*5入組</td>\n",
       "      <td>22469</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>320</td>\n",
       "      <td>中壢區</td>\n",
       "      <td>米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味</td>\n",
       "      <td>2019-08-02 16:38:00</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  gender  invoice_no invoice_date invoice_time  \\\n",
       "0           1    Male      536544   2018-11-29     14:32:00   \n",
       "1         100  Female      539453   2018-12-15     17:08:00   \n",
       "2        1000    Male      561820   2019-07-27     16:00:00   \n",
       "3        1009    Male      562417   2019-08-02     16:32:00   \n",
       "4        1010  Female      562420   2019-08-02     16:38:00   \n",
       "\n",
       "         product_name product_code  unit_price  quantity  subtotal  region_id  \\\n",
       "0  王子麵-火鍋/滷味專用50g*5入組        22469          35         3       105        324   \n",
       "1  王子麵-火鍋/滷味專用50g*5入組        22469          35         4       140        320   \n",
       "2  王子麵-火鍋/滷味專用50g*5入組        22469          35         1        35        333   \n",
       "3  王子麵-火鍋/滷味專用50g*5入組        22469          35         4       140        327   \n",
       "4  王子麵-火鍋/滷味專用50g*5入組        22469          35         1        35        320   \n",
       "\n",
       "  region_name             category_name            date_time  bought_rate  \\\n",
       "0         平鎮區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2018-11-29 14:32:00     0.002732   \n",
       "1         中壢區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2018-12-15 17:08:00     0.002732   \n",
       "2         龜山區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2019-07-27 16:00:00     0.002732   \n",
       "3         新屋區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2019-08-02 16:32:00     0.002732   \n",
       "4         中壢區  米油沖泡_泡麵．麵條_米粉．麵條_米粉及其它口味  2019-08-02 16:38:00     0.002732   \n",
       "\n",
       "   quantity_quartile  price_quartile  bought_rate_quartile  \n",
       "0                  5               1                     5  \n",
       "1                  5               1                     5  \n",
       "2                  3               1                     5  \n",
       "3                  5               1                     5  \n",
       "4                  3               1                     5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出均分的門檻值\n",
    "quantiles = df.quantile(q=[0.2,0.4,0.6,0.8]).to_dict()\n",
    "print(quantiles)\n",
    "\n",
    "# 按照門檻值, 由小到大, 搭配 apply, 回傳 1, 2, 3, 4, 5\n",
    "def quantity_class(x,k,d):\n",
    "    if x < d[k][0.2]:\n",
    "        return 1\n",
    "    elif x < d[k][0.4]:\n",
    "        return 2\n",
    "    elif x < d[k][0.6]:\n",
    "        return 3\n",
    "    elif x < d[k][0.8]:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "def price_class(x,k,d):\n",
    "    if x < d[k][0.2]:\n",
    "        return 1\n",
    "    elif x < d[k][0.4]:\n",
    "        return 2\n",
    "    elif x < d[k][0.6]:\n",
    "        return 3\n",
    "    elif x < d[k][0.8]:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "def buy_index_class(x,k,d):\n",
    "    if x < d[k][0.2]:\n",
    "        return 1\n",
    "    elif x < d[k][0.4]:\n",
    "        return 2\n",
    "    elif x < d[k][0.6]:\n",
    "        return 3\n",
    "    elif x < d[k][0.8]:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "df['quantity_quartile'] = df['quantity'].apply(quantity_class, args=('quantity',quantiles,))\n",
    "df['price_quartile'] = df['unit_price'].apply(price_class, args=('unit_price',quantiles,))\n",
    "df['bought_rate_quartile'] = df['bought_rate'].apply(buy_index_class, args=('bought_rate',quantiles,))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 轉換資料型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_id'] = df['customer_id'].apply(lambda x : str(x))\n",
    "df['product_code'] = df['product_code'].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 產生用戶對商品的評分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設計權重(0.1 ~ 0.8排列組合)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list =[\n",
    "             [0.1,0.1,0.8,(0.1,0.1,0.8)],\n",
    "             [0.1,0.2,0.7,(0.1,0.2,0.7)],\n",
    "             [0.1,0.3,0.6,(0.1,0.3,0.6)],\n",
    "             [0.1,0.4,0.5,(0.1,0.4,0.5)],\n",
    "             [0.1,0.5,0.4,(0.1,0.5,0.4)],\n",
    "             [0.1,0.6,0.3,(0.1,0.6,0.3)],\n",
    "             [0.1,0.7,0.2,(0.1,0.7,0.2)],\n",
    "             [0.1,0.8,0.1,(0.1,0.8,0.1)],\n",
    "\n",
    "             [0.2,0.1,0.7,(0.2,0.1,0.7)],\n",
    "             [0.2,0.2,0.6,(0.2,0.2,0.6)],\n",
    "             [0.2,0.3,0.5,(0.2,0.3,0.5)],\n",
    "             [0.2,0.4,0.4,(0.2,0.4,0.4)],\n",
    "             [0.2,0.5,0.3,(0.2,0.5,0.3)],\n",
    "             [0.2,0.6,0.2,(0.2,0.6,0.2)],\n",
    "             [0.2,0.7,0.1,(0.2,0.7,0.1)],\n",
    "\n",
    "             [0.3,0.1,0.6,(0.3,0.1,0.6)],\n",
    "             [0.3,0.2,0.5,(0.3,0.2,0.5)],\n",
    "             [0.3,0.3,0.4,(0.3,0.3,0.4)],\n",
    "             [0.3,0.4,0.3,(0.3,0.4,0.3)],\n",
    "             [0.3,0.5,0.2,(0.3,0.5,0.2)],\n",
    "             [0.3,0.6,0.1,(0.3,0.6,0.1)],\n",
    "\n",
    "             [0.4,0.1,0.5,(0.4,0.1,0.5)],\n",
    "             [0.4,0.2,0.4,(0.4,0.2,0.4)],\n",
    "             [0.4,0.3,0.3,(0.4,0.3,0.3)],\n",
    "             [0.4,0.4,0.2,(0.4,0.4,0.2)],\n",
    "             [0.4,0.5,0.1,(0.4,0.5,0.1)],\n",
    "\n",
    "             [0.5,0.1,0.4,(0.5,0.1,0.4)],\n",
    "             [0.5,0.2,0.3,(0.5,0.2,0.3)],\n",
    "             [0.5,0.3,0.2,(0.5,0.3,0.2)],\n",
    "             [0.5,0.4,0.1,(0.5,0.4,0.1)],\n",
    "\n",
    "             [0.6,0.1,0.3,(0.6,0.1,0.3)],\n",
    "             [0.6,0.2,0.2,(0.6,0.2,0.2)],\n",
    "             [0.6,0.3,0.1,(0.6,0.3,0.1)],\n",
    "\n",
    "             [0.7,0.1,0.2,(0.7,0.1,0.2)],\n",
    "             [0.7,0.2,0.1,(0.7,0.2,0.1)],\n",
    "\n",
    "             [0.8,0.1,0.1,(0.8,0.1,0.1)],    \n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依照設定的權重，產出評分，這邊以(0.2, 0.3, 0.5為例)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11001</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16236</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16237</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16238</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17003</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id product_code  rating\n",
       "0           1        11001     3.0\n",
       "1           1        16236     1.9\n",
       "2           1        16237     3.7\n",
       "3           1        16238     3.1\n",
       "4           1        17003     4.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rating(df,quantity_weight, price_weight, buy_rate_weight):\n",
    "    #依權重新增'rating'欄位\n",
    "    df['rating'] = df['quantity_quartile'] * quantity_weight \\\n",
    "                 + df['price_quartile'] * price_weight \\\n",
    "                 + df['bought_rate_quartile'] * buy_rate_weight\n",
    "    # 建造customerID的list, 並去掉重複值\n",
    "    customer_id_list = df['customer_id'].tolist()\n",
    "    customer_id_list = list(set(customer_id_list))\n",
    "    \n",
    "    # 把顧客購物清單上, 重複的商品rating做平均, 回傳新的df, 欄位為['customer_id','product_code','rating']\n",
    "    rating_df = df.groupby(by = ['customer_id','product_code'], as_index=False).agg({'rating': lambda x : x.mean()})\n",
    "    return rating_df\n",
    "rating_df = get_rating(df,0.2,0.3,0.5)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 固定用KNN演算法，找出RMSE最小的權重組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 4993.507181882858 秒\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119237</td>\n",
       "      <td>(0.1, 0.4, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120656</td>\n",
       "      <td>(0.1, 0.5, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121115</td>\n",
       "      <td>(0.1, 0.3, 0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.127454</td>\n",
       "      <td>(0.1, 0.2, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128018</td>\n",
       "      <td>(0.1, 0.6, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137903</td>\n",
       "      <td>(0.1, 0.1, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.139991</td>\n",
       "      <td>(0.1, 0.7, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.142034</td>\n",
       "      <td>(0.2, 0.4, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.143969</td>\n",
       "      <td>(0.2, 0.3, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.144504</td>\n",
       "      <td>(0.2, 0.5, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.148741</td>\n",
       "      <td>(0.2, 0.2, 0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.151423</td>\n",
       "      <td>(0.2, 0.6, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.155463</td>\n",
       "      <td>(0.1, 0.8, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.157114</td>\n",
       "      <td>(0.2, 0.1, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.162462</td>\n",
       "      <td>(0.2, 0.7, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.173783</td>\n",
       "      <td>(0.3, 0.4, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.174083</td>\n",
       "      <td>(0.3, 0.3, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.177706</td>\n",
       "      <td>(0.3, 0.5, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.177822</td>\n",
       "      <td>(0.3, 0.2, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.185357</td>\n",
       "      <td>(0.3, 0.1, 0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.185560</td>\n",
       "      <td>(0.3, 0.6, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.210368</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.211816</td>\n",
       "      <td>(0.4, 0.4, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.211890</td>\n",
       "      <td>(0.4, 0.2, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.217090</td>\n",
       "      <td>(0.4, 0.5, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.217484</td>\n",
       "      <td>(0.4, 0.1, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.251212</td>\n",
       "      <td>(0.5, 0.2, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.251222</td>\n",
       "      <td>(0.5, 0.3, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.254482</td>\n",
       "      <td>(0.5, 0.4, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.254578</td>\n",
       "      <td>(0.5, 0.1, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.294105</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.295243</td>\n",
       "      <td>(0.6, 0.1, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.295844</td>\n",
       "      <td>(0.6, 0.3, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.339516</td>\n",
       "      <td>(0.7, 0.1, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.339553</td>\n",
       "      <td>(0.7, 0.2, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.385490</td>\n",
       "      <td>(0.8, 0.1, 0.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_rmse           weight\n",
       "3    0.119237  (0.1, 0.4, 0.5)\n",
       "4    0.120656  (0.1, 0.5, 0.4)\n",
       "2    0.121115  (0.1, 0.3, 0.6)\n",
       "1    0.127454  (0.1, 0.2, 0.7)\n",
       "5    0.128018  (0.1, 0.6, 0.3)\n",
       "0    0.137903  (0.1, 0.1, 0.8)\n",
       "6    0.139991  (0.1, 0.7, 0.2)\n",
       "11   0.142034  (0.2, 0.4, 0.4)\n",
       "10   0.143969  (0.2, 0.3, 0.5)\n",
       "12   0.144504  (0.2, 0.5, 0.3)\n",
       "9    0.148741  (0.2, 0.2, 0.6)\n",
       "13   0.151423  (0.2, 0.6, 0.2)\n",
       "7    0.155463  (0.1, 0.8, 0.1)\n",
       "8    0.157114  (0.2, 0.1, 0.7)\n",
       "14   0.162462  (0.2, 0.7, 0.1)\n",
       "18   0.173783  (0.3, 0.4, 0.3)\n",
       "17   0.174083  (0.3, 0.3, 0.4)\n",
       "19   0.177706  (0.3, 0.5, 0.2)\n",
       "16   0.177822  (0.3, 0.2, 0.5)\n",
       "15   0.185357  (0.3, 0.1, 0.6)\n",
       "20   0.185560  (0.3, 0.6, 0.1)\n",
       "23   0.210368  (0.4, 0.3, 0.3)\n",
       "24   0.211816  (0.4, 0.4, 0.2)\n",
       "22   0.211890  (0.4, 0.2, 0.4)\n",
       "25   0.217090  (0.4, 0.5, 0.1)\n",
       "21   0.217484  (0.4, 0.1, 0.5)\n",
       "27   0.251212  (0.5, 0.2, 0.3)\n",
       "28   0.251222  (0.5, 0.3, 0.2)\n",
       "29   0.254482  (0.5, 0.4, 0.1)\n",
       "26   0.254578  (0.5, 0.1, 0.4)\n",
       "31   0.294105  (0.6, 0.2, 0.2)\n",
       "30   0.295243  (0.6, 0.1, 0.3)\n",
       "32   0.295844  (0.6, 0.3, 0.1)\n",
       "33   0.339516  (0.7, 0.1, 0.2)\n",
       "34   0.339553  (0.7, 0.2, 0.1)\n",
       "35   0.385490  (0.8, 0.1, 0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "rmse_w_df = pd.DataFrame(columns=['test_rmse','weight'])\n",
    "for w in weight_list:\n",
    "    rating_df = get_rating(df,w[0], w[1], w[2])\n",
    "    # 需要reader, 並設定評分範圍(1~5)\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    # 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "    data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "    \n",
    "    #設定演算法\n",
    "    sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "    bsl_options = {'method': 'als', #sgd 隨機梯度下降法   #als交替最小二乘法\n",
    "                   'n_epochs': 20,}\n",
    "    algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "    \n",
    "    #Perform cross validation\n",
    "    results = cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    # get rmse\n",
    "    rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "    \n",
    "    rmse_w_df = rmse_w_df.append({'test_rmse':rmse,'weight':w[3]},ignore_index=True)\n",
    "print('花了',time.time()-t1, '秒')\n",
    "rmse_w_df.sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11001</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16236</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16237</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16238</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17003</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id product_code  rating\n",
       "0           1        11001     3.0\n",
       "1           1        16236     1.7\n",
       "2           1        16237     3.6\n",
       "3           1        16238     3.3\n",
       "4           1        17003     4.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由上可看出權重(0.1, 0.4, 0.5)的RMSE最小，所以用此評分去跑模型\n",
    "rating_df = get_rating(df,0.1,0.4,0.5)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 帶入最好的評分資料，找出最適合的模型, 用RMSE檢測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在執行： BaselineOnly\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "正在執行： SVD\n",
      "正在執行： SlopeOne\n",
      "正在執行： CoClustering\n",
      "正在執行： NMF\n",
      "正在執行： NormalPredictor\n",
      "正在執行： KNNBaseline\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "正在執行： KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "正在執行： KNNWithMeans\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "正在執行： KNNWithZScore\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "time: 609.7806658744812\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.068848</td>\n",
       "      <td>5.151736</td>\n",
       "      <td>29.797526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.072872</td>\n",
       "      <td>4.434458</td>\n",
       "      <td>25.082671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>0.093943</td>\n",
       "      <td>15.616691</td>\n",
       "      <td>1.138872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.124356</td>\n",
       "      <td>15.389640</td>\n",
       "      <td>1.217127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.147441</td>\n",
       "      <td>0.685961</td>\n",
       "      <td>0.816160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.188197</td>\n",
       "      <td>4.614262</td>\n",
       "      <td>28.237112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.201675</td>\n",
       "      <td>5.393145</td>\n",
       "      <td>30.086217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.257305</td>\n",
       "      <td>3.173763</td>\n",
       "      <td>16.727873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.533752</td>\n",
       "      <td>6.587989</td>\n",
       "      <td>0.929713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.133228</td>\n",
       "      <td>0.401926</td>\n",
       "      <td>1.256713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse   fit_time  test_time\n",
       "Algorithm                                       \n",
       "KNNBaseline       0.068848   5.151736  29.797526\n",
       "KNNBasic          0.072872   4.434458  25.082671\n",
       "NMF               0.093943  15.616691   1.138872\n",
       "SVD               0.124356  15.389640   1.217127\n",
       "BaselineOnly      0.147441   0.685961   0.816160\n",
       "KNNWithMeans      0.188197   4.614262  28.237112\n",
       "KNNWithZScore     0.201675   5.393145  30.086217\n",
       "SlopeOne          0.257305   3.173763  16.727873\n",
       "CoClustering      0.533752   6.587989   0.929713\n",
       "NormalPredictor   1.133228   0.401926   1.256713"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Surprise庫, 進行不同算法的預測, 並以rmse檢測\n",
    "t1 = time.time()\n",
    "benchmark = []\n",
    "\n",
    "#Iterate over all algorithms\n",
    "\n",
    "for algorithm in [BaselineOnly(), SVD(), SlopeOne(), CoClustering(), NMF(), NormalPredictor(), \n",
    "                  KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore()] :\n",
    "    # 觀察進度用\n",
    "    print('正在執行：',str(algorithm).split(' ')[0].split('.')[-1])\n",
    "    \n",
    "    #Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "algorithm_test_df = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')\n",
    "print('time:',time.time()-t1)\n",
    "algorithm_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由上可知，KNNBaseline的RMSE數值是最小的，選用此來當作演算法。\n",
    "### 調整裡面的參數，找到最RMSE最小的參數組合。(鄰近目標, 相似度計算方式, 誤差優化器, 跌代次數)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一組cosine + user_based + als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 176.97992372512817 秒\n",
      "rmse: 0.07330058173318056\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "bsl_options = {'method': 'als', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二組cosine + user_based + sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 171.79921555519104 秒\n",
      "rmse: 0.06666711032616866\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "bsl_options = {'method': 'sgd', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三組cosine + item_based + als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 143.0716187953949 秒\n",
      "rmse: 0.1523224052439256\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "bsl_options = {'method': 'als', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四組cosine + item_based + sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 144.48915481567383 秒\n",
      "rmse: 0.10815593641106382\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "bsl_options = {'method': 'sgd', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第五組pearson_baseline + user_based + als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 167.42470049858093 秒\n",
      "rmse: 0.07294185677283781\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "bsl_options = {'method': 'als', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第六組pearson_baseline + user_based + sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 170.33070945739746 秒\n",
      "rmse: 0.06630383250632088\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "bsl_options = {'method': 'sgd', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第七組pearson_baseline + item_based + als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 143.32236289978027 秒\n",
      "rmse: 0.11953677479680225\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "bsl_options = {'method': 'als', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第八組pearson_baseline + item_based + sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "花了 143.76690769195557 秒\n",
      "rmse: 0.09735261447124512\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "rating_df = get_rating(df,0.1, 0.4, 0.5)\n",
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "#設定演算法\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "bsl_options = {'method': 'sgd', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "#Perform cross validation\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "\n",
    "# get rmse\n",
    "rmse = pd.DataFrame.from_dict(results).mean(axis=0)['test_rmse']\n",
    "\n",
    "print('花了',time.time()-t1, '秒')\n",
    "print('rmse:',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.1104\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.1082\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.1068\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.1072\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.1082\n"
     ]
    }
   ],
   "source": [
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)\n",
    "\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "bsl_options = {'method': 'als', #sgd 随机梯度下降法   #als交替最小二乘法\n",
    "               'n_epochs': 20,}\n",
    "algo = KNNBaseline(40,1,sim_options=sim_options,bsl_options=bsl_options)\n",
    "\n",
    "\n",
    "\n",
    "# 使用KFord作為交叉驗證\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item_Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據讀取 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到相似項目 : sim_options中的user_based設置為false，基於項目相似度做計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x294017f0cc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型訓練\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "bsl_options = {'method': 'als','n_epochs': 20}\n",
    "all_trainset = data.build_full_trainset()\n",
    "item_algo = KNNBaseline(40, 1, sim_options=sim_options, bsl_options=bsl_options)\n",
    "item_algo.fit(all_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22980',\n",
       " '22982',\n",
       " '11001',\n",
       " '16236',\n",
       " '16237',\n",
       " '16238',\n",
       " '17003',\n",
       " '17011F',\n",
       " '17012A',\n",
       " '17012B']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出相似物品的Top-N list\n",
    "def getSimilarItems(top_k,item_id):\n",
    "    item_inner_id = item_algo.trainset.to_inner_iid(item_id)\n",
    "    item_neighbors = item_algo.get_neighbors(item_inner_id, k=top_k)\n",
    "    f_item_neighbors = (item_algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in item_neighbors)\n",
    "    return list(f_item_neighbors)\n",
    "# 測試\n",
    "getSimilarItems(10,'23843')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除list裡的重複值\n",
    "def deleteDuplicatedElementFromList(l):\n",
    "    resultList = []\n",
    "    for item in l:\n",
    "        if not item in resultList:\n",
    "            resultList.append(item)\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertProductCode2Name(L):\n",
    "    # 推薦列表轉 DataFrame\n",
    "    recommend_item_df = pd.DataFrame(L,columns = ['product_code'])\n",
    "    \n",
    "    # 建立商品Code與Name對應的 Dataframe\n",
    "    product_code_name_df = pd.DataFrame({'product_code':df['product_code'],'product_name':df['product_name']}).drop_duplicates()\n",
    "    \n",
    "    # 將兩個 DataFrame做 merge\n",
    "    recommend_item_df = pd.merge(recommend_item_df,product_code_name_df, on = ['product_code'])\n",
    "    \n",
    "    # 商品名輸出成list\n",
    "    recommend_item_list = list(recommend_item_df['product_name'])\n",
    "    return recommend_item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemBasedRecommender(customer_id):\n",
    "    # 建立每個顧客的購買清單 DataFrame\n",
    "    customer_itemList_df = df.groupby('customer_id', as_index = False).agg({'product_code': lambda x : ' '.join(x).split(' ')})\n",
    "    \n",
    "    # 建立特定顧客的購買物品list\n",
    "    customer_items_list = customer_itemList_df[customer_itemList_df['customer_id'] == customer_id]['product_code'].values[0]\n",
    "    \n",
    "    # 每個購買產品, 推薦10個相似物, 放進lsit [[A1,A2,..,A10], [B1,B2,...,B10],...]\n",
    "    total_list = []\n",
    "    for item in customer_items_list:\n",
    "        tmp_item_list = getSimilarItems(10, item)\n",
    "        total_list.append(tmp_item_list)\n",
    "        \n",
    "    # 用 S 型的方式將推薦品放進list [A1,B1,C1,A2,B2,C2,.....]    \n",
    "    recommend_list = []\n",
    "    for t in range(10):\n",
    "        for l in total_list:\n",
    "            recommend_list.append(l[t])\n",
    "            \n",
    "    # 推薦列表中, 刪除已購買過的產品\n",
    "    for i in customer_items_list:\n",
    "        if i in recommend_list:\n",
    "            recommend_list.remove(i)\n",
    "    # 將推薦商品code_list 轉成 name_list\n",
    "    recommend_list = convertProductCode2Name(recommend_list)\n",
    "    recommend_list = deleteDuplicatedElementFromList(recommend_list)\n",
    "    return recommend_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['家樂福巴黎美妝馬賽香皂-羅勒哈密瓜-100gx2',\n",
       " '乖乖桶-720g',\n",
       " '日安黑檀筷-5雙入',\n",
       " '滿漢大餐麻辣鍋牛肉(碗) 204g',\n",
       " '義美純豬肉鬆-海苔芝麻175g',\n",
       " 'keyway名廚標準量水杯600cc',\n",
       " '動物系列兒童雨衣-小豬粉 L',\n",
       " '黑蒜頭100g',\n",
       " 'DG舒適條紋女踝襪(黑)',\n",
       " '韓國isLeaf極緻水感保濕面膜22ml-膠原蛋白']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試 推薦 customer_id = '1'\n",
    "itemBasedRecommender('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User_Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據讀取 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要reader, 並設定評分範圍(1~5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# 資料欄位必須照著順序, 依序為['user_Id','item_Id','rating']\n",
    "data = Dataset.load_from_df(rating_df[['customer_id', 'product_code', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到相似用戶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x2940ab711c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "sim_options={'name':'cosine','user_based': True}\n",
    "bsl_options = {'method': 'als','n_epochs': 20}\n",
    "all_trainset = data.build_full_trainset()\n",
    "user_algo = KNNBasic(k=40, min_k=3, sim_options = sim_options, bsl_options = bsl_options)\n",
    "user_algo.fit(all_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14195',\n",
       " '14836',\n",
       " '15049',\n",
       " '16462',\n",
       " '270',\n",
       " '839',\n",
       " '1006',\n",
       " '1011',\n",
       " '103',\n",
       " '104']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出相似用戶的Top-N\n",
    "def getSimilarUsers(top_k,u_id):\n",
    "    user_inner_id = user_algo.trainset.to_inner_uid(u_id)\n",
    "    user_neighbors = user_algo.get_neighbors(user_inner_id, k=top_k)\n",
    "    user_neighbors = (user_algo.trainset.to_raw_uid(inner_id) for inner_id in user_neighbors)\n",
    "    return list(user_neighbors)\n",
    "# 測試\n",
    "getSimilarUsers(10, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除list裡的重複值\n",
    "def deleteDuplicatedElementFromList(l):\n",
    "    resultList = []\n",
    "    for item in l:\n",
    "        if not item in resultList:\n",
    "            resultList.append(item)\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertProductCode2Name(L):\n",
    "    # 推薦列表轉 DataFrame\n",
    "    recommend_item_df = pd.DataFrame(L,columns = ['product_code'])\n",
    "    \n",
    "    # 建立商品Code與Name對應的 Dataframe\n",
    "    product_code_name_df = pd.DataFrame({'product_code':df['product_code'],'product_name':df['product_name']}).drop_duplicates()\n",
    "    \n",
    "    # 將兩個 DataFrame做 merge\n",
    "    recommend_item_df = pd.merge(recommend_item_df,product_code_name_df, on = ['product_code'])\n",
    "    \n",
    "    # 商品名輸出成list\n",
    "    recommend_item_list = list(recommend_item_df['product_name'])\n",
    "    return recommend_item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userBasedRecommender(customer_id):\n",
    "    # 建立每個顧客的購買清單 DataFrame\n",
    "    customer_itemList_df = df.groupby('customer_id', as_index = False).agg({'product_code': lambda x : ' '.join(x).split(' ')})\n",
    "    \n",
    "    # 建立 Top 10 的 similar users list\n",
    "    similar_users_list = getSimilarUsers(10, customer_id)\n",
    "    \n",
    "     # 建立特定顧客的購買物品list\n",
    "    customer_items_list = customer_itemList_df[customer_itemList_df['customer_id'] == customer_id]['product_code'].values[0]\n",
    "    \n",
    "    # 建立 similar users 購買物品 list [[A1,A2,.], [B1,B2,..],...]\n",
    "    similar_user_item_list = []\n",
    "    for user in similar_users_list:\n",
    "        item_list = customer_itemList_df[customer_itemList_df['customer_id'] == user]['product_code'].values[0]\n",
    "        similar_user_item_list.append(item_list)\n",
    "        \n",
    "    # 建立推薦物品list [A1,A2,...,B1,B2,...]    \n",
    "    recommend_list = []\n",
    "    for l in similar_user_item_list:\n",
    "        for item in l:\n",
    "            recommend_list.append(item)\n",
    "    # 推薦列表中, 刪除已購買過的產品\n",
    "    for i in customer_items_list:\n",
    "        if i in recommend_list:\n",
    "            recommend_list.remove(i)\n",
    "    # 將推薦商品code_list 轉成 name_list\n",
    "    recommend_list = convertProductCode2Name(recommend_list)\n",
    "    recommend_list = deleteDuplicatedElementFromList(recommend_list)\n",
    "    return recommend_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['哈根達斯 冰淇淋品脫 抹茶 473ml',\n",
       " '愛貓機能餐罐(鮪魚+牛肉)85g',\n",
       " '瑪榭腳踝加強直條紋輕護足弓襪-LF-顏色隨機',\n",
       " '西班牙Torres 鵝肝風味洋芋片-150g',\n",
       " '米森有機黑森林野莓茶4g*8包',\n",
       " 'Farcent香水室內擴香-自由雛菊-120ml',\n",
       " 'BVD W跟超低襪口男隱形襪',\n",
       " '滿鍋香-濃香原味150g',\n",
       " '寶多福健康犬餐-熟齡小型犬-3.5kg',\n",
       " '樂天小熊餅家庭號-香濃煉乳風味-195g']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試\n",
    "userBasedRecommender('1200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_algo.predict(iid = '17011F', uid = '14987')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from surprise import dump\n",
    "\n",
    "# Compute predictions of the 'original' algorithm.\n",
    "predictions = user_algo.test(all_trainset.build_testset())\n",
    "\n",
    "# Dump algorithm and reload it.\n",
    "file_name = os.path.expanduser('~/dump_file')\n",
    "dump.dump(file_name, algo=user_algo)\n",
    "loaded_algo = dump.load(file_name)\n",
    "\n",
    "# We now ensure that the algo is still the same by checking the predictions.\n",
    "predictions_loaded_algo = loaded_algo[1].test(all_trainset.build_testset())\n",
    "assert predictions == predictions_loaded_algo\n",
    "print('Predictions are the same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_loaded_algo = loaded_algo[1].test(all_trainset.build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions == predictions_loaded_algo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
